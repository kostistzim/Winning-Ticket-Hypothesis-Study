{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-09T14:46:50.788484Z",
     "start_time": "2025-11-09T14:46:49.045087Z"
    }
   },
   "source": [
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michalisdikaiopoulos/Desktop/Master/Autumn2025/Advanced Topics in Deep Learning/Assignments/Assignment_2/Winning-Ticket-Hypothesis-Study/.venv/lib/python3.9/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T14:46:56.113632Z",
     "start_time": "2025-11-09T14:46:56.107230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CHECKPOINTS = [\n",
    "    \"./new_models/lottery_ticket_sst2_sparsity60_seed42.pt\",\n",
    "    \"./new_models/lottery_ticket_sst2_sparsity60_seed123.pt\",\n",
    "]"
   ],
   "id": "a7e8fd6bb81810c8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T14:47:09.486190Z",
     "start_time": "2025-11-09T14:47:09.453089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def verify_checkpoint(checkpoint_path):\n",
    "    \"\"\"Thoroughly inspect a checkpoint file.\"\"\"\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"ğŸ“¦ Inspecting: {os.path.basename(checkpoint_path)}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(f\"âŒ File not found: {checkpoint_path}\")\n",
    "        return None\n",
    "\n",
    "    # Load checkpoint\n",
    "    try:\n",
    "        ckpt = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to load checkpoint: {e}\")\n",
    "        return None\n",
    "\n",
    "    # --- Checkpoint Structure ---\n",
    "    print(\"\\nğŸ” Checkpoint Keys:\")\n",
    "    for key in ckpt.keys():\n",
    "        print(f\"   - {key}\")\n",
    "\n",
    "    # --- Model State Dict ---\n",
    "    if \"model_state_dict\" in ckpt:\n",
    "        state_dict = ckpt[\"model_state_dict\"]\n",
    "        print(f\"\\nğŸ§  Model State Dict: {len(state_dict)} keys\")\n",
    "\n",
    "        # Categorize keys\n",
    "        bert_keys = [k for k in state_dict.keys() if k.startswith(\"bert.\")]\n",
    "        classifier_keys = [k for k in state_dict.keys() if k.startswith(\"classifier\")]\n",
    "        other_keys = [k for k in state_dict.keys() if not k.startswith(\"bert.\") and not k.startswith(\"classifier\")]\n",
    "\n",
    "        print(f\"   - BERT encoder keys: {len(bert_keys)}\")\n",
    "        print(f\"   - Classifier keys: {len(classifier_keys)}\")\n",
    "        if other_keys:\n",
    "            print(f\"   - Other keys: {len(other_keys)}\")\n",
    "\n",
    "        # Show classifier shape\n",
    "        if classifier_keys:\n",
    "            print(f\"\\n   ğŸ“Š Classifier layers:\")\n",
    "            for key in classifier_keys:\n",
    "                shape = state_dict[key].shape\n",
    "                print(f\"      {key}: {shape}\")\n",
    "\n",
    "        # Sample BERT weights\n",
    "        print(f\"\\n   ğŸ”¬ Sample BERT weights (first 3):\")\n",
    "        for key in list(bert_keys)[:3]:\n",
    "            shape = state_dict[key].shape\n",
    "            print(f\"      {key}: {shape}\")\n",
    "\n",
    "    # --- Mask Information ---\n",
    "    if \"mask_dict\" in ckpt:\n",
    "        mask_dict = ckpt[\"mask_dict\"]\n",
    "        print(f\"\\nğŸ­ Mask Dict: {len(mask_dict)} masks found\")\n",
    "\n",
    "        # Count masked parameters\n",
    "        total_params = 0\n",
    "        total_nonzero = 0\n",
    "\n",
    "        for key, mask in mask_dict.items():\n",
    "            total_params += mask.numel()\n",
    "            total_nonzero += mask.sum().item()\n",
    "\n",
    "        sparsity = (1 - total_nonzero / total_params) * 100\n",
    "        print(f\"   - Total parameters: {total_params:,}\")\n",
    "        print(f\"   - Non-zero parameters: {total_nonzero:,}\")\n",
    "        print(f\"   - Sparsity: {sparsity:.2f}%\")\n",
    "\n",
    "        # Show some mask keys\n",
    "        print(f\"\\n   ğŸ”¬ Sample mask keys (first 3):\")\n",
    "        for key in list(mask_dict.keys())[:3]:\n",
    "            shape = mask_dict[key].shape\n",
    "            nonzero = mask_dict[key].sum().item()\n",
    "            total = mask_dict[key].numel()\n",
    "            print(f\"      {key}: {shape} -> {nonzero}/{total} active ({nonzero/total*100:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  No mask_dict found - this might be a dense model (sparsity 0)\")\n",
    "\n",
    "    # --- Training Metadata ---\n",
    "    metadata_keys = [\"task\", \"seed\", \"sparsity\", \"final_accuracy\", \"best_val_acc\"]\n",
    "    print(f\"\\nğŸ“‹ Training Metadata:\")\n",
    "    for key in metadata_keys:\n",
    "        if key in ckpt:\n",
    "            print(f\"   - {key}: {ckpt[key]}\")\n",
    "\n",
    "    # Check for any other metadata\n",
    "    other_metadata = [k for k in ckpt.keys() if k not in [\"model_state_dict\", \"mask_dict\"] + metadata_keys]\n",
    "    if other_metadata:\n",
    "        print(f\"\\n   Additional metadata:\")\n",
    "        for key in other_metadata:\n",
    "            value = ckpt[key]\n",
    "            if isinstance(value, (int, float, str, bool)):\n",
    "                print(f\"   - {key}: {value}\")\n",
    "            else:\n",
    "                print(f\"   - {key}: {type(value)}\")\n",
    "\n",
    "    # --- Verification Summary ---\n",
    "    print(f\"\\nâœ… Verification Summary:\")\n",
    "    has_encoder = \"model_state_dict\" in ckpt and len([k for k in ckpt[\"model_state_dict\"].keys() if k.startswith(\"bert.\")]) > 0\n",
    "    has_classifier = \"model_state_dict\" in ckpt and len([k for k in ckpt[\"model_state_dict\"].keys() if k.startswith(\"classifier\")]) > 0\n",
    "    has_mask = \"mask_dict\" in ckpt\n",
    "\n",
    "    print(f\"   âœ“ BERT encoder weights: {'âœ…' if has_encoder else 'âŒ'}\")\n",
    "    print(f\"   âœ“ Classifier weights: {'âœ…' if has_classifier else 'âŒ'}\")\n",
    "    print(f\"   âœ“ Lottery ticket mask: {'âœ…' if has_mask else 'âš ï¸  (dense model)'}\")\n",
    "\n",
    "    return {\n",
    "        \"path\": checkpoint_path,\n",
    "        \"has_encoder\": has_encoder,\n",
    "        \"has_classifier\": has_classifier,\n",
    "        \"has_mask\": has_mask,\n",
    "        \"sparsity\": sparsity if has_mask else 0.0,\n",
    "    }"
   ],
   "id": "2b8b63910b7a72e7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T14:47:21.775187Z",
     "start_time": "2025-11-09T14:47:21.766690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def verify_all_checkpoints(checkpoint_list):\n",
    "    \"\"\"Verify all checkpoints and create summary report.\"\"\"\n",
    "\n",
    "    print(\"\\n\" + \"ğŸ”¬\"*35)\n",
    "    print(\"LOTTERY TICKET CHECKPOINT VERIFICATION\")\n",
    "    print(\"ğŸ”¬\"*35)\n",
    "\n",
    "    results = []\n",
    "    for ckpt_path in checkpoint_list:\n",
    "        result = verify_checkpoint(ckpt_path)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "\n",
    "    # --- Summary Table ---\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ“Š SUMMARY TABLE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"{'Checkpoint':<50} {'Encoder':<10} {'Mask':<10} {'Sparsity':<10}\")\n",
    "    print(\"-\"*70)\n",
    "\n",
    "    for result in results:\n",
    "        name = os.path.basename(result[\"path\"])\n",
    "        encoder = \"âœ…\" if result[\"has_encoder\"] else \"âŒ\"\n",
    "        mask = \"âœ…\" if result[\"has_mask\"] else \"âš ï¸\"\n",
    "        sparsity = f\"{result['sparsity']:.1f}%\"\n",
    "        print(f\"{name:<50} {encoder:<10} {mask:<10} {sparsity:<10}\")\n",
    "\n",
    "    print(\"\\nâœ… Verification complete!\\n\")\n",
    "    return results"
   ],
   "id": "7160e2f409b0aacb",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T14:47:30.818312Z",
     "start_time": "2025-11-09T14:47:30.806809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_transfer_compatibility(source_checkpoint, target_task):\n",
    "    \"\"\"Check if a checkpoint is compatible for transfer to target task.\"\"\"\n",
    "\n",
    "    print(f\"\\nğŸ”„ Checking transfer compatibility:\")\n",
    "    print(f\"   Source: {os.path.basename(source_checkpoint)}\")\n",
    "    print(f\"   Target: {target_task.upper()}\")\n",
    "\n",
    "    ckpt = torch.load(source_checkpoint, map_location=\"cpu\")\n",
    "    state_dict = ckpt.get(\"model_state_dict\", {})\n",
    "\n",
    "    # Check BERT encoder\n",
    "    bert_keys = [k for k in state_dict.keys() if k.startswith(\"bert.\")]\n",
    "    if not bert_keys:\n",
    "        print(\"   âŒ No BERT encoder found!\")\n",
    "        return False\n",
    "\n",
    "    print(f\"   âœ… BERT encoder: {len(bert_keys)} parameters\")\n",
    "\n",
    "    # Check mask (for lottery tickets)\n",
    "    if \"mask_dict\" in ckpt:\n",
    "        mask_dict = ckpt[\"mask_dict\"]\n",
    "        total = sum(m.numel() for m in mask_dict.values())\n",
    "        nonzero = sum(m.sum().item() for m in mask_dict.values())\n",
    "        print(f\"   âœ… Lottery mask: {(1-nonzero/total)*100:.1f}% sparse\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸  No mask found (dense model)\")\n",
    "\n",
    "    # Check classifier (will be reinitialized anyway)\n",
    "    classifier_keys = [k for k in state_dict.keys() if k.startswith(\"classifier\")]\n",
    "    if classifier_keys:\n",
    "        print(f\"   â„¹ï¸  Classifier found (will be reinitialized for {target_task})\")\n",
    "\n",
    "    print(f\"   âœ… Compatible for transfer learning!\")\n",
    "    return True"
   ],
   "id": "68d82c8d5af920df",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T16:11:16.266506Z",
     "start_time": "2025-11-09T16:11:14.930140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Verify all checkpoints\n",
    "    results = verify_all_checkpoints(CHECKPOINTS)"
   ],
   "id": "80d2f0266b7efd92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬\n",
      "LOTTERY TICKET CHECKPOINT VERIFICATION\n",
      "ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬\n",
      "\n",
      "======================================================================\n",
      "ğŸ“¦ Inspecting: lottery_ticket_qqp_sparsity70_seed42.pt\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Checkpoint Keys:\n",
      "   - model_state_dict\n",
      "   - sparsity\n",
      "   - seed\n",
      "   - history\n",
      "\n",
      "ğŸ§  Model State Dict: 203 keys\n",
      "   - BERT encoder keys: 0\n",
      "   - Classifier keys: 0\n",
      "   - Other keys: 203\n",
      "\n",
      "   ğŸ”¬ Sample BERT weights (first 3):\n",
      "\n",
      "âš ï¸  No mask_dict found - this might be a dense model (sparsity 0)\n",
      "\n",
      "ğŸ“‹ Training Metadata:\n",
      "   - seed: 42\n",
      "   - sparsity: 0.7\n",
      "\n",
      "   Additional metadata:\n",
      "   - history: <class 'dict'>\n",
      "\n",
      "âœ… Verification Summary:\n",
      "   âœ“ BERT encoder weights: âŒ\n",
      "   âœ“ Classifier weights: âŒ\n",
      "   âœ“ Lottery ticket mask: âš ï¸  (dense model)\n",
      "\n",
      "======================================================================\n",
      "ğŸ“¦ Inspecting: lottery_ticket_sst2_sparsity60_seed42.pt\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Checkpoint Keys:\n",
      "   - model_state_dict\n",
      "   - sparsity\n",
      "   - seed\n",
      "   - history\n",
      "\n",
      "ğŸ§  Model State Dict: 203 keys\n",
      "   - BERT encoder keys: 0\n",
      "   - Classifier keys: 0\n",
      "   - Other keys: 203\n",
      "\n",
      "   ğŸ”¬ Sample BERT weights (first 3):\n",
      "\n",
      "âš ï¸  No mask_dict found - this might be a dense model (sparsity 0)\n",
      "\n",
      "ğŸ“‹ Training Metadata:\n",
      "   - seed: 42\n",
      "   - sparsity: 0.6\n",
      "\n",
      "   Additional metadata:\n",
      "   - history: <class 'dict'>\n",
      "\n",
      "âœ… Verification Summary:\n",
      "   âœ“ BERT encoder weights: âŒ\n",
      "   âœ“ Classifier weights: âŒ\n",
      "   âœ“ Lottery ticket mask: âš ï¸  (dense model)\n",
      "\n",
      "======================================================================\n",
      "ğŸ“¦ Inspecting: ensemble_ticket_sst2_qqp_sparsity47_seed42.pt\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Checkpoint Keys:\n",
      "   - model_state_dict\n",
      "   - source_a\n",
      "   - source_b\n",
      "   - seed\n",
      "   - sparsity\n",
      "   - tasks\n",
      "\n",
      "ğŸ§  Model State Dict: 203 keys\n",
      "   - BERT encoder keys: 0\n",
      "   - Classifier keys: 0\n",
      "   - Other keys: 203\n",
      "\n",
      "   ğŸ”¬ Sample BERT weights (first 3):\n",
      "\n",
      "âš ï¸  No mask_dict found - this might be a dense model (sparsity 0)\n",
      "\n",
      "ğŸ“‹ Training Metadata:\n",
      "   - seed: 42\n",
      "   - sparsity: 0.4694054029107775\n",
      "\n",
      "   Additional metadata:\n",
      "   - source_a: <class 'dict'>\n",
      "   - source_b: <class 'dict'>\n",
      "   - tasks: <class 'list'>\n",
      "\n",
      "âœ… Verification Summary:\n",
      "   âœ“ BERT encoder weights: âŒ\n",
      "   âœ“ Classifier weights: âŒ\n",
      "   âœ“ Lottery ticket mask: âš ï¸  (dense model)\n",
      "\n",
      "======================================================================\n",
      "ğŸ“¦ Inspecting: lottery_ticket_qqp_sparsity0_seed42.pt\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Checkpoint Keys:\n",
      "   - model_state_dict\n",
      "   - sparsity\n",
      "   - seed\n",
      "   - history\n",
      "\n",
      "ğŸ§  Model State Dict: 203 keys\n",
      "   - BERT encoder keys: 0\n",
      "   - Classifier keys: 0\n",
      "   - Other keys: 203\n",
      "\n",
      "   ğŸ”¬ Sample BERT weights (first 3):\n",
      "\n",
      "âš ï¸  No mask_dict found - this might be a dense model (sparsity 0)\n",
      "\n",
      "ğŸ“‹ Training Metadata:\n",
      "   - seed: 42\n",
      "   - sparsity: 0.0\n",
      "\n",
      "   Additional metadata:\n",
      "   - history: <class 'dict'>\n",
      "\n",
      "âœ… Verification Summary:\n",
      "   âœ“ BERT encoder weights: âŒ\n",
      "   âœ“ Classifier weights: âŒ\n",
      "   âœ“ Lottery ticket mask: âš ï¸  (dense model)\n",
      "\n",
      "======================================================================\n",
      "ğŸ“¦ Inspecting: lottery_ticket_sst2_sparsity0_seed42.pt\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Checkpoint Keys:\n",
      "   - model_state_dict\n",
      "   - sparsity\n",
      "   - seed\n",
      "   - history\n",
      "\n",
      "ğŸ§  Model State Dict: 203 keys\n",
      "   - BERT encoder keys: 0\n",
      "   - Classifier keys: 0\n",
      "   - Other keys: 203\n",
      "\n",
      "   ğŸ”¬ Sample BERT weights (first 3):\n",
      "\n",
      "âš ï¸  No mask_dict found - this might be a dense model (sparsity 0)\n",
      "\n",
      "ğŸ“‹ Training Metadata:\n",
      "   - seed: 42\n",
      "   - sparsity: 0.0\n",
      "\n",
      "   Additional metadata:\n",
      "   - history: <class 'dict'>\n",
      "\n",
      "âœ… Verification Summary:\n",
      "   âœ“ BERT encoder weights: âŒ\n",
      "   âœ“ Classifier weights: âŒ\n",
      "   âœ“ Lottery ticket mask: âš ï¸  (dense model)\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š SUMMARY TABLE\n",
      "======================================================================\n",
      "Checkpoint                                         Encoder    Mask       Sparsity  \n",
      "----------------------------------------------------------------------\n",
      "lottery_ticket_qqp_sparsity70_seed42.pt            âŒ          âš ï¸         0.0%      \n",
      "lottery_ticket_sst2_sparsity60_seed42.pt           âŒ          âš ï¸         0.0%      \n",
      "ensemble_ticket_sst2_qqp_sparsity47_seed42.pt      âŒ          âš ï¸         0.0%      \n",
      "lottery_ticket_qqp_sparsity0_seed42.pt             âŒ          âš ï¸         0.0%      \n",
      "lottery_ticket_sst2_sparsity0_seed42.pt            âŒ          âš ï¸         0.0%      \n",
      "\n",
      "âœ… Verification complete!\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T16:14:25.265389Z",
     "start_time": "2025-11-09T16:14:25.229032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Directory containing your JSON files\n",
    "folder_path = \"./fewshot_models\"  # change this to your folder\n",
    "\n",
    "combined_data = []\n",
    "\n",
    "# Loop through all .json files\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                combined_data.append(data)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"âš ï¸ Skipping {filename}: invalid JSON ({e})\")\n",
    "\n",
    "# Convert combined data to a single JSON string\n",
    "combined_json_str = json.dumps(combined_data, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Print or save the combined string\n",
    "print(combined_json_str)\n",
    "\n",
    "# Optional: save to file\n",
    "# with open(\"combined.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(combined_json_str)\n"
   ],
   "id": "fad7817ed3605679",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/lottery_ticket_qqp_sparsity70_seed42.pt\",\n",
      "    \"target_task\": \"sst2\",\n",
      "    \"mode\": \"headonly\",\n",
      "    \"seed\": 42,\n",
      "    \"train_acc\": 0.609375,\n",
      "    \"val_acc\": 0.625,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/ensemble_ticket_sst2_qqp_sparsity47_seed42.pt\",\n",
      "    \"target_task\": \"sst2\",\n",
      "    \"mode\": \"full\",\n",
      "    \"seed\": 42,\n",
      "    \"train_acc\": 0.8359375,\n",
      "    \"val_acc\": 0.8125,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/lottery_ticket_qqp_sparsity70_seed999.pt\",\n",
      "    \"target_task\": \"sst2\",\n",
      "    \"mode\": \"headonly\",\n",
      "    \"seed\": 999,\n",
      "    \"train_acc\": 0.4921875,\n",
      "    \"val_acc\": 0.4375,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/lottery_ticket_qqp_sparsity70_seed123.pt\",\n",
      "    \"target_task\": \"sst2\",\n",
      "    \"mode\": \"headonly\",\n",
      "    \"seed\": 123,\n",
      "    \"train_acc\": 0.546875,\n",
      "    \"val_acc\": 0.5625,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/lottery_ticket_qqp_sparsity70_seed42.pt\",\n",
      "    \"target_task\": \"sst2\",\n",
      "    \"mode\": \"full\",\n",
      "    \"seed\": 42,\n",
      "    \"train_acc\": 0.8359375,\n",
      "    \"val_acc\": 0.8125,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/lottery_ticket_sst2_sparsity60_seed42.pt\",\n",
      "    \"target_task\": \"qqp\",\n",
      "    \"mode\": \"full\",\n",
      "    \"seed\": 42,\n",
      "    \"train_acc\": 0.640625,\n",
      "    \"val_acc\": 0.6875,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/lottery_ticket_sst2_sparsity0_seed42.pt\",\n",
      "    \"target_task\": \"qqp\",\n",
      "    \"mode\": \"headonly\",\n",
      "    \"seed\": 42,\n",
      "    \"train_acc\": 0.640625,\n",
      "    \"val_acc\": 0.6875,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/ensemble_ticket_sst2_qqp_sparsity47_seed42.pt\",\n",
      "    \"target_task\": \"qqp\",\n",
      "    \"mode\": \"full\",\n",
      "    \"seed\": 42,\n",
      "    \"train_acc\": 0.640625,\n",
      "    \"val_acc\": 0.6875,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/lottery_ticket_qqp_sparsity0_seed42.pt\",\n",
      "    \"target_task\": \"sst2\",\n",
      "    \"mode\": \"full\",\n",
      "    \"seed\": 42,\n",
      "    \"train_acc\": 0.8359375,\n",
      "    \"val_acc\": 0.8125,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/ensemble_ticket_sst2_qqp_sparsity47_seed999.pt\",\n",
      "    \"target_task\": \"sst2\",\n",
      "    \"mode\": \"full\",\n",
      "    \"seed\": 999,\n",
      "    \"train_acc\": 0.8671875,\n",
      "    \"val_acc\": 0.78125,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/lottery_ticket_sst2_sparsity60_seed42.pt\",\n",
      "    \"target_task\": \"qqp\",\n",
      "    \"mode\": \"headonly\",\n",
      "    \"seed\": 42,\n",
      "    \"train_acc\": 0.640625,\n",
      "    \"val_acc\": 0.6875,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/ensemble_ticket_sst2_qqp_sparsity47_seed123.pt\",\n",
      "    \"target_task\": \"sst2\",\n",
      "    \"mode\": \"full\",\n",
      "    \"seed\": 123,\n",
      "    \"train_acc\": 0.78125,\n",
      "    \"val_acc\": 0.5625,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/lottery_ticket_qqp_sparsity0_seed123.pt\",\n",
      "    \"target_task\": \"sst2\",\n",
      "    \"mode\": \"full\",\n",
      "    \"seed\": 123,\n",
      "    \"train_acc\": 0.78125,\n",
      "    \"val_acc\": 0.5625,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/lottery_ticket_qqp_sparsity0_seed999.pt\",\n",
      "    \"target_task\": \"sst2\",\n",
      "    \"mode\": \"full\",\n",
      "    \"seed\": 999,\n",
      "    \"train_acc\": 0.8671875,\n",
      "    \"val_acc\": 0.78125,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/ensemble_ticket_sst2_qqp_sparsity47_seed999.pt\",\n",
      "    \"target_task\": \"sst2\",\n",
      "    \"mode\": \"headonly\",\n",
      "    \"seed\": 999,\n",
      "    \"train_acc\": 0.4921875,\n",
      "    \"val_acc\": 0.4375,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/ensemble_ticket_sst2_qqp_sparsity47_seed999.pt\",\n",
      "    \"target_task\": \"qqp\",\n",
      "    \"mode\": \"headonly\",\n",
      "    \"seed\": 999,\n",
      "    \"train_acc\": 0.578125,\n",
      "    \"val_acc\": 0.53125,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/lottery_ticket_qqp_sparsity0_seed42.pt\",\n",
      "    \"target_task\": \"sst2\",\n",
      "    \"mode\": \"headonly\",\n",
      "    \"seed\": 42,\n",
      "    \"train_acc\": 0.609375,\n",
      "    \"val_acc\": 0.625,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/ensemble_ticket_sst2_qqp_sparsity47_seed123.pt\",\n",
      "    \"target_task\": \"qqp\",\n",
      "    \"mode\": \"headonly\",\n",
      "    \"seed\": 123,\n",
      "    \"train_acc\": 0.640625,\n",
      "    \"val_acc\": 0.65625,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/ensemble_ticket_sst2_qqp_sparsity47_seed123.pt\",\n",
      "    \"target_task\": \"sst2\",\n",
      "    \"mode\": \"headonly\",\n",
      "    \"seed\": 123,\n",
      "    \"train_acc\": 0.546875,\n",
      "    \"val_acc\": 0.5625,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/lottery_ticket_sst2_sparsity0_seed42.pt\",\n",
      "    \"target_task\": \"qqp\",\n",
      "    \"mode\": \"full\",\n",
      "    \"seed\": 42,\n",
      "    \"train_acc\": 0.640625,\n",
      "    \"val_acc\": 0.6875,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/lottery_ticket_sst2_sparsity60_seed123.pt\",\n",
      "    \"target_task\": \"qqp\",\n",
      "    \"mode\": \"full\",\n",
      "    \"seed\": 123,\n",
      "    \"train_acc\": 0.640625,\n",
      "    \"val_acc\": 0.6875,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/lottery_ticket_qqp_sparsity70_seed123.pt\",\n",
      "    \"target_task\": \"sst2\",\n",
      "    \"mode\": \"full\",\n",
      "    \"seed\": 123,\n",
      "    \"train_acc\": 0.78125,\n",
      "    \"val_acc\": 0.5625,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/lottery_ticket_sst2_sparsity60_seed999.pt\",\n",
      "    \"target_task\": \"qqp\",\n",
      "    \"mode\": \"full\",\n",
      "    \"seed\": 999,\n",
      "    \"train_acc\": 0.640625,\n",
      "    \"val_acc\": 0.6875,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/lottery_ticket_qqp_sparsity70_seed999.pt\",\n",
      "    \"target_task\": \"sst2\",\n",
      "    \"mode\": \"full\",\n",
      "    \"seed\": 999,\n",
      "    \"train_acc\": 0.8671875,\n",
      "    \"val_acc\": 0.78125,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/ensemble_ticket_sst2_qqp_sparsity47_seed123.pt\",\n",
      "    \"target_task\": \"qqp\",\n",
      "    \"mode\": \"full\",\n",
      "    \"seed\": 123,\n",
      "    \"train_acc\": 0.640625,\n",
      "    \"val_acc\": 0.6875,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/ensemble_ticket_sst2_qqp_sparsity47_seed999.pt\",\n",
      "    \"target_task\": \"qqp\",\n",
      "    \"mode\": \"full\",\n",
      "    \"seed\": 999,\n",
      "    \"train_acc\": 0.640625,\n",
      "    \"val_acc\": 0.6875,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/ensemble_ticket_sst2_qqp_sparsity47_seed42.pt\",\n",
      "    \"target_task\": \"sst2\",\n",
      "    \"mode\": \"headonly\",\n",
      "    \"seed\": 42,\n",
      "    \"train_acc\": 0.609375,\n",
      "    \"val_acc\": 0.625,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/lottery_ticket_sst2_sparsity60_seed999.pt\",\n",
      "    \"target_task\": \"qqp\",\n",
      "    \"mode\": \"headonly\",\n",
      "    \"seed\": 999,\n",
      "    \"train_acc\": 0.578125,\n",
      "    \"val_acc\": 0.53125,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/lottery_ticket_qqp_sparsity0_seed999.pt\",\n",
      "    \"target_task\": \"sst2\",\n",
      "    \"mode\": \"headonly\",\n",
      "    \"seed\": 999,\n",
      "    \"train_acc\": 0.4921875,\n",
      "    \"val_acc\": 0.4375,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/lottery_ticket_qqp_sparsity0_seed123.pt\",\n",
      "    \"target_task\": \"sst2\",\n",
      "    \"mode\": \"headonly\",\n",
      "    \"seed\": 123,\n",
      "    \"train_acc\": 0.546875,\n",
      "    \"val_acc\": 0.5625,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/lottery_ticket_sst2_sparsity60_seed123.pt\",\n",
      "    \"target_task\": \"qqp\",\n",
      "    \"mode\": \"headonly\",\n",
      "    \"seed\": 123,\n",
      "    \"train_acc\": 0.640625,\n",
      "    \"val_acc\": 0.65625,\n",
      "    \"examples\": 128\n",
      "  },\n",
      "  {\n",
      "    \"source_checkpoint\": \"./models/ensemble_ticket_sst2_qqp_sparsity47_seed42.pt\",\n",
      "    \"target_task\": \"qqp\",\n",
      "    \"mode\": \"headonly\",\n",
      "    \"seed\": 42,\n",
      "    \"train_acc\": 0.640625,\n",
      "    \"val_acc\": 0.6875,\n",
      "    \"examples\": 128\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T16:53:47.013624Z",
     "start_time": "2025-11-09T16:53:46.964719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "# Folder where your summary JSONs are saved\n",
    "summary_dir = \"./models\"\n",
    "\n",
    "for fname in os.listdir(summary_dir):\n",
    "    if not fname.endswith(\"_summary.json\"):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(summary_dir, fname)\n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    task = data[\"task\"]\n",
    "    seed = data[\"seed\"]\n",
    "    sparsity = data[\"sparsity\"]\n",
    "    hist = data[\"history\"]\n",
    "\n",
    "    # Get first and last entries\n",
    "    train_acc_dense = hist[\"train_acc\"][0]\n",
    "    val_acc_dense = hist[\"val_acc\"][0]\n",
    "    train_acc_target = hist[\"train_acc\"][-1]\n",
    "    val_acc_target = hist[\"val_acc\"][-1]\n",
    "\n",
    "    results.append({\n",
    "        \"task\": task,\n",
    "        \"seed\": seed,\n",
    "        \"target_sparsity\": sparsity,\n",
    "        \"train_acc_dense\": train_acc_dense,\n",
    "        \"val_acc_dense\": val_acc_dense,\n",
    "        \"train_acc_target\": train_acc_target,\n",
    "        \"val_acc_target\": val_acc_target,\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Sort for readability\n",
    "df = df.sort_values(by=[\"task\", \"seed\", \"target_sparsity\"]).reset_index(drop=True)\n",
    "\n",
    "# Print summary\n",
    "print(df)\n",
    "\n",
    "# Optionally, save to CSV\n",
    "out_path = os.path.join(summary_dir, \"lottery_ticket_results_table.csv\")\n",
    "df.to_csv(out_path, index=False)\n",
    "print(f\"\\nâœ… Results table saved to {out_path}\")\n"
   ],
   "id": "1d0b877b5b7afdff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    task  seed  target_sparsity  train_acc_dense  val_acc_dense  \\\n",
      "0    qqp    42              0.0         0.822447       0.861995   \n",
      "1    qqp    42              0.7         0.822447       0.861995   \n",
      "2    qqp   123              0.0         0.820962       0.861283   \n",
      "3    qqp   123              0.7         0.820962       0.861283   \n",
      "4    qqp   999              0.0         0.820012       0.860392   \n",
      "5    qqp   999              0.7         0.820012       0.860392   \n",
      "6   sst2    42              0.0         0.911921       0.923165   \n",
      "7   sst2    42              0.6         0.911921       0.923165   \n",
      "8   sst2   123              0.0         0.908477       0.918578   \n",
      "9   sst2   123              0.6         0.908477       0.918578   \n",
      "10  sst2   999              0.0         0.913005       0.916284   \n",
      "11  sst2   999              0.6         0.913005       0.916284   \n",
      "\n",
      "    train_acc_target  val_acc_target  \n",
      "0           0.822447        0.861995  \n",
      "1           0.979513        0.865736  \n",
      "2           0.820962        0.861283  \n",
      "3           0.978904        0.865380  \n",
      "4           0.820012        0.860392  \n",
      "5           0.978845        0.867696  \n",
      "6           0.911921        0.923165  \n",
      "7           0.995293        0.911697  \n",
      "8           0.908477        0.918578  \n",
      "9           0.995382        0.918578  \n",
      "10          0.913005        0.916284  \n",
      "11          0.995056        0.918578  \n",
      "\n",
      "âœ… Results table saved to ./models/lottery_ticket_results_table.csv\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T16:56:44.489550Z",
     "start_time": "2025-11-09T16:56:44.456510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "fewshot_dir = \"./fewshot_models\"\n",
    "records = []\n",
    "\n",
    "for fname in os.listdir(fewshot_dir):\n",
    "    if not fname.endswith(\".json\") or not fname.startswith(\"fewshot_\"):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(fewshot_dir, fname)\n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # --- Extract main info from JSON ---\n",
    "    target_task = data.get(\"target_task\", \"unknown\")\n",
    "    mode = data.get(\"mode\", \"unknown\")\n",
    "    seed = data.get(\"seed\", None)\n",
    "    train_acc = data.get(\"train_acc\", None)\n",
    "    val_acc = data.get(\"val_acc\", None)\n",
    "    examples = data.get(\"examples\", None)\n",
    "    source_checkpoint = data.get(\"source_checkpoint\", \"\")\n",
    "\n",
    "    # --- Parse source checkpoint name ---\n",
    "    source_type = \"unknown\"\n",
    "    source_tasks = \"unknown\"\n",
    "    sparsity = None\n",
    "\n",
    "    m = re.search(r\"(lottery_ticket|ensemble_ticket)_([a-zA-Z0-9_]+)_sparsity(\\d+)_seed(\\d+)\", source_checkpoint)\n",
    "    if m:\n",
    "        source_type = m.group(1).replace(\"_ticket\", \"\")\n",
    "        source_tasks = m.group(2).replace(\"_\", \"+\")  # e.g., sst2_qqp â†’ sst2+qqp\n",
    "        sparsity = float(m.group(3)) / 100.0\n",
    "\n",
    "    records.append({\n",
    "        \"target_task\": target_task,\n",
    "        \"source_type\": source_type,\n",
    "        \"source_tasks\": source_tasks,\n",
    "        \"sparsity\": sparsity,\n",
    "        \"seed\": seed,\n",
    "        \"mode\": mode,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"examples\": examples,\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df = df.sort_values(by=[\"target_task\", \"source_type\", \"sparsity\", \"mode\", \"seed\"]).reset_index(drop=True)\n",
    "\n",
    "print(df)\n",
    "\n",
    "out_path = os.path.join(fewshot_dir, \"fewshot_results_table.csv\")\n",
    "df.to_csv(out_path, index=False)\n",
    "print(f\"\\nâœ… Few-shot results table saved to {out_path}\")\n"
   ],
   "id": "598c0c4795ca89a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   target_task source_type source_tasks  sparsity  seed      mode  train_acc  \\\n",
      "0          qqp    ensemble     sst2+qqp      0.47    42      full   0.640625   \n",
      "1          qqp    ensemble     sst2+qqp      0.47   123      full   0.640625   \n",
      "2          qqp    ensemble     sst2+qqp      0.47   999      full   0.640625   \n",
      "3          qqp    ensemble     sst2+qqp      0.47    42  headonly   0.640625   \n",
      "4          qqp    ensemble     sst2+qqp      0.47   123  headonly   0.640625   \n",
      "5          qqp    ensemble     sst2+qqp      0.47   999  headonly   0.578125   \n",
      "6          qqp     lottery         sst2      0.00    42      full   0.640625   \n",
      "7          qqp     lottery         sst2      0.00   123      full   0.640625   \n",
      "8          qqp     lottery         sst2      0.00   999      full   0.640625   \n",
      "9          qqp     lottery         sst2      0.00    42  headonly   0.640625   \n",
      "10         qqp     lottery         sst2      0.00   123  headonly   0.640625   \n",
      "11         qqp     lottery         sst2      0.00   999  headonly   0.578125   \n",
      "12         qqp     lottery         sst2      0.60    42      full   0.640625   \n",
      "13         qqp     lottery         sst2      0.60   123      full   0.640625   \n",
      "14         qqp     lottery         sst2      0.60   999      full   0.640625   \n",
      "15         qqp     lottery         sst2      0.60    42  headonly   0.640625   \n",
      "16         qqp     lottery         sst2      0.60   123  headonly   0.640625   \n",
      "17         qqp     lottery         sst2      0.60   999  headonly   0.578125   \n",
      "18        sst2    ensemble     sst2+qqp      0.47    42      full   0.835938   \n",
      "19        sst2    ensemble     sst2+qqp      0.47   123      full   0.781250   \n",
      "20        sst2    ensemble     sst2+qqp      0.47   999      full   0.867188   \n",
      "21        sst2    ensemble     sst2+qqp      0.47    42  headonly   0.609375   \n",
      "22        sst2    ensemble     sst2+qqp      0.47   123  headonly   0.546875   \n",
      "23        sst2    ensemble     sst2+qqp      0.47   999  headonly   0.492188   \n",
      "24        sst2     lottery          qqp      0.00    42      full   0.835938   \n",
      "25        sst2     lottery          qqp      0.00   123      full   0.781250   \n",
      "26        sst2     lottery          qqp      0.00   999      full   0.867188   \n",
      "27        sst2     lottery          qqp      0.00    42  headonly   0.609375   \n",
      "28        sst2     lottery          qqp      0.00   123  headonly   0.546875   \n",
      "29        sst2     lottery          qqp      0.00   999  headonly   0.492188   \n",
      "30        sst2     lottery          qqp      0.70    42      full   0.835938   \n",
      "31        sst2     lottery          qqp      0.70   123      full   0.781250   \n",
      "32        sst2     lottery          qqp      0.70   999      full   0.867188   \n",
      "33        sst2     lottery          qqp      0.70    42  headonly   0.609375   \n",
      "34        sst2     lottery          qqp      0.70   123  headonly   0.546875   \n",
      "35        sst2     lottery          qqp      0.70   999  headonly   0.492188   \n",
      "\n",
      "    val_acc  examples  \n",
      "0   0.68750       128  \n",
      "1   0.68750       128  \n",
      "2   0.68750       128  \n",
      "3   0.68750       128  \n",
      "4   0.65625       128  \n",
      "5   0.53125       128  \n",
      "6   0.68750       128  \n",
      "7   0.68750       128  \n",
      "8   0.68750       128  \n",
      "9   0.68750       128  \n",
      "10  0.65625       128  \n",
      "11  0.53125       128  \n",
      "12  0.68750       128  \n",
      "13  0.68750       128  \n",
      "14  0.68750       128  \n",
      "15  0.68750       128  \n",
      "16  0.65625       128  \n",
      "17  0.53125       128  \n",
      "18  0.81250       128  \n",
      "19  0.56250       128  \n",
      "20  0.78125       128  \n",
      "21  0.62500       128  \n",
      "22  0.56250       128  \n",
      "23  0.43750       128  \n",
      "24  0.81250       128  \n",
      "25  0.56250       128  \n",
      "26  0.78125       128  \n",
      "27  0.62500       128  \n",
      "28  0.56250       128  \n",
      "29  0.43750       128  \n",
      "30  0.81250       128  \n",
      "31  0.56250       128  \n",
      "32  0.78125       128  \n",
      "33  0.62500       128  \n",
      "34  0.56250       128  \n",
      "35  0.43750       128  \n",
      "\n",
      "âœ… Few-shot results table saved to ./fewshot_models/fewshot_results_table.csv\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:12:41.602760Z",
     "start_time": "2025-11-09T19:12:38.927539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing all model .pt files\n",
    "model_dir = \"./models\"\n",
    "\n",
    "# --- Helper functions ---\n",
    "def flatten_weights(state_dict):\n",
    "    \"\"\"Return dict of flattened tensors for all linear layers.\"\"\"\n",
    "    flat = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if not isinstance(v, torch.Tensor):\n",
    "            continue\n",
    "        # Ignore biases and embeddings\n",
    "        if v.ndim >= 2 and \"embeddings\" not in k and \"LayerNorm\" not in k:\n",
    "            flat[k] = v.flatten()\n",
    "    return flat\n",
    "\n",
    "def cosine_similarity_models(path_a, path_b):\n",
    "    \"\"\"Compute mean cosine similarity between two model state dicts.\"\"\"\n",
    "    wa = torch.load(path_a, map_location=\"cpu\")[\"model_state_dict\"]\n",
    "    wb = torch.load(path_b, map_location=\"cpu\")[\"model_state_dict\"]\n",
    "\n",
    "    fa, fb = flatten_weights(wa), flatten_weights(wb)\n",
    "    sims = []\n",
    "    for k in fa:\n",
    "        if k in fb and fa[k].numel() == fb[k].numel():\n",
    "            sims.append(F.cosine_similarity(fa[k], fb[k], dim=0).item())\n",
    "\n",
    "    return float(np.mean(sims)) if sims else np.nan\n",
    "\n",
    "# --- Collect ticket paths ---\n",
    "tickets = [f for f in os.listdir(model_dir) if f.startswith(\"lottery_ticket\") and f.endswith(\".pt\")]\n",
    "tickets = [f for f in tickets if not \"sparsity0\" in f]  # exclude dense models\n",
    "\n",
    "sst2_tickets = [f for f in tickets if \"_sst2_\" in f]\n",
    "qqp_tickets  = [f for f in tickets if \"_qqp_\" in f]\n",
    "\n",
    "records = []\n",
    "\n",
    "# --- Compare same-seed SST2 vs QQP ---\n",
    "for sst_file in sst2_tickets:\n",
    "    m = re.search(r\"sparsity(\\d+)_seed(\\d+)\", sst_file)\n",
    "    if not m:\n",
    "        continue\n",
    "    sparsity_sst2, seed = int(m.group(1)) / 100.0, int(m.group(2))\n",
    "\n",
    "    # Find matching qqp file with same seed\n",
    "    qqp_file = next((f for f in qqp_tickets if f\"seed{seed}\" in f), None)\n",
    "    if qqp_file is None:\n",
    "        continue\n",
    "\n",
    "    m2 = re.search(r\"sparsity(\\d+)_seed(\\d+)\", qqp_file)\n",
    "    sparsity_qqp = int(m2.group(1)) / 100.0\n",
    "\n",
    "    path_sst2 = os.path.join(model_dir, sst_file)\n",
    "    path_qqp = os.path.join(model_dir, qqp_file)\n",
    "\n",
    "    sim = cosine_similarity_models(path_sst2, path_qqp)\n",
    "\n",
    "    records.append({\n",
    "        \"seed\": seed,\n",
    "        \"sst2_sparsity\": sparsity_sst2,\n",
    "        \"qqp_sparsity\": sparsity_qqp,\n",
    "        \"cosine_similarity\": sim,\n",
    "        \"sst2_model\": sst_file,\n",
    "        \"qqp_model\": qqp_file,\n",
    "    })\n",
    "\n",
    "# --- Create DataFrame ---\n",
    "df = pd.DataFrame(records)\n",
    "df = df.sort_values(by=\"seed\").reset_index(drop=True)\n",
    "\n",
    "print(df)\n",
    "\n",
    "out_path = os.path.join(model_dir, \"cross_task_cosine_similarity.csv\")\n",
    "df.to_csv(out_path, index=False)\n",
    "print(f\"\\nâœ… Saved similarity table to {out_path}\")\n"
   ],
   "id": "49db57c6db96d464",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   seed  sst2_sparsity  qqp_sparsity  cosine_similarity  \\\n",
      "0    42            0.6           0.7           0.933109   \n",
      "1   123            0.6           0.7           0.932258   \n",
      "2   999            0.6           0.7           0.932612   \n",
      "\n",
      "                                  sst2_model  \\\n",
      "0   lottery_ticket_sst2_sparsity60_seed42.pt   \n",
      "1  lottery_ticket_sst2_sparsity60_seed123.pt   \n",
      "2  lottery_ticket_sst2_sparsity60_seed999.pt   \n",
      "\n",
      "                                  qqp_model  \n",
      "0   lottery_ticket_qqp_sparsity70_seed42.pt  \n",
      "1  lottery_ticket_qqp_sparsity70_seed123.pt  \n",
      "2  lottery_ticket_qqp_sparsity70_seed999.pt  \n",
      "\n",
      "âœ… Saved similarity table to ./models/cross_task_cosine_similarity.csv\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1a1538e4ade3e58b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Winning-Ticket",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
