{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-09T14:46:50.788484Z",
     "start_time": "2025-11-09T14:46:49.045087Z"
    }
   },
   "source": [
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michalisdikaiopoulos/Desktop/Master/Autumn2025/Advanced Topics in Deep Learning/Assignments/Assignment_2/Winning-Ticket-Hypothesis-Study/.venv/lib/python3.9/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T14:46:56.113632Z",
     "start_time": "2025-11-09T14:46:56.107230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CHECKPOINTS = [\n",
    "    \"./models/lottery_ticket_qqp_sparsity70_seed42.pt\",\n",
    "    \"./models/lottery_ticket_sst2_sparsity60_seed42.pt\",\n",
    "    \"./models/ensemble_ticket_sst2_qqp_sparsity47_seed42.pt\",\n",
    "    \"./models/lottery_ticket_qqp_sparsity0_seed42.pt\",\n",
    "    \"./models/lottery_ticket_sst2_sparsity0_seed42.pt\",\n",
    "]"
   ],
   "id": "a7e8fd6bb81810c8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T14:47:09.486190Z",
     "start_time": "2025-11-09T14:47:09.453089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def verify_checkpoint(checkpoint_path):\n",
    "    \"\"\"Thoroughly inspect a checkpoint file.\"\"\"\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"ğŸ“¦ Inspecting: {os.path.basename(checkpoint_path)}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(f\"âŒ File not found: {checkpoint_path}\")\n",
    "        return None\n",
    "\n",
    "    # Load checkpoint\n",
    "    try:\n",
    "        ckpt = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to load checkpoint: {e}\")\n",
    "        return None\n",
    "\n",
    "    # --- Checkpoint Structure ---\n",
    "    print(\"\\nğŸ” Checkpoint Keys:\")\n",
    "    for key in ckpt.keys():\n",
    "        print(f\"   - {key}\")\n",
    "\n",
    "    # --- Model State Dict ---\n",
    "    if \"model_state_dict\" in ckpt:\n",
    "        state_dict = ckpt[\"model_state_dict\"]\n",
    "        print(f\"\\nğŸ§  Model State Dict: {len(state_dict)} keys\")\n",
    "\n",
    "        # Categorize keys\n",
    "        bert_keys = [k for k in state_dict.keys() if k.startswith(\"bert.\")]\n",
    "        classifier_keys = [k for k in state_dict.keys() if k.startswith(\"classifier\")]\n",
    "        other_keys = [k for k in state_dict.keys() if not k.startswith(\"bert.\") and not k.startswith(\"classifier\")]\n",
    "\n",
    "        print(f\"   - BERT encoder keys: {len(bert_keys)}\")\n",
    "        print(f\"   - Classifier keys: {len(classifier_keys)}\")\n",
    "        if other_keys:\n",
    "            print(f\"   - Other keys: {len(other_keys)}\")\n",
    "\n",
    "        # Show classifier shape\n",
    "        if classifier_keys:\n",
    "            print(f\"\\n   ğŸ“Š Classifier layers:\")\n",
    "            for key in classifier_keys:\n",
    "                shape = state_dict[key].shape\n",
    "                print(f\"      {key}: {shape}\")\n",
    "\n",
    "        # Sample BERT weights\n",
    "        print(f\"\\n   ğŸ”¬ Sample BERT weights (first 3):\")\n",
    "        for key in list(bert_keys)[:3]:\n",
    "            shape = state_dict[key].shape\n",
    "            print(f\"      {key}: {shape}\")\n",
    "\n",
    "    # --- Mask Information ---\n",
    "    if \"mask_dict\" in ckpt:\n",
    "        mask_dict = ckpt[\"mask_dict\"]\n",
    "        print(f\"\\nğŸ­ Mask Dict: {len(mask_dict)} masks found\")\n",
    "\n",
    "        # Count masked parameters\n",
    "        total_params = 0\n",
    "        total_nonzero = 0\n",
    "\n",
    "        for key, mask in mask_dict.items():\n",
    "            total_params += mask.numel()\n",
    "            total_nonzero += mask.sum().item()\n",
    "\n",
    "        sparsity = (1 - total_nonzero / total_params) * 100\n",
    "        print(f\"   - Total parameters: {total_params:,}\")\n",
    "        print(f\"   - Non-zero parameters: {total_nonzero:,}\")\n",
    "        print(f\"   - Sparsity: {sparsity:.2f}%\")\n",
    "\n",
    "        # Show some mask keys\n",
    "        print(f\"\\n   ğŸ”¬ Sample mask keys (first 3):\")\n",
    "        for key in list(mask_dict.keys())[:3]:\n",
    "            shape = mask_dict[key].shape\n",
    "            nonzero = mask_dict[key].sum().item()\n",
    "            total = mask_dict[key].numel()\n",
    "            print(f\"      {key}: {shape} -> {nonzero}/{total} active ({nonzero/total*100:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  No mask_dict found - this might be a dense model (sparsity 0)\")\n",
    "\n",
    "    # --- Training Metadata ---\n",
    "    metadata_keys = [\"task\", \"seed\", \"sparsity\", \"final_accuracy\", \"best_val_acc\"]\n",
    "    print(f\"\\nğŸ“‹ Training Metadata:\")\n",
    "    for key in metadata_keys:\n",
    "        if key in ckpt:\n",
    "            print(f\"   - {key}: {ckpt[key]}\")\n",
    "\n",
    "    # Check for any other metadata\n",
    "    other_metadata = [k for k in ckpt.keys() if k not in [\"model_state_dict\", \"mask_dict\"] + metadata_keys]\n",
    "    if other_metadata:\n",
    "        print(f\"\\n   Additional metadata:\")\n",
    "        for key in other_metadata:\n",
    "            value = ckpt[key]\n",
    "            if isinstance(value, (int, float, str, bool)):\n",
    "                print(f\"   - {key}: {value}\")\n",
    "            else:\n",
    "                print(f\"   - {key}: {type(value)}\")\n",
    "\n",
    "    # --- Verification Summary ---\n",
    "    print(f\"\\nâœ… Verification Summary:\")\n",
    "    has_encoder = \"model_state_dict\" in ckpt and len([k for k in ckpt[\"model_state_dict\"].keys() if k.startswith(\"bert.\")]) > 0\n",
    "    has_classifier = \"model_state_dict\" in ckpt and len([k for k in ckpt[\"model_state_dict\"].keys() if k.startswith(\"classifier\")]) > 0\n",
    "    has_mask = \"mask_dict\" in ckpt\n",
    "\n",
    "    print(f\"   âœ“ BERT encoder weights: {'âœ…' if has_encoder else 'âŒ'}\")\n",
    "    print(f\"   âœ“ Classifier weights: {'âœ…' if has_classifier else 'âŒ'}\")\n",
    "    print(f\"   âœ“ Lottery ticket mask: {'âœ…' if has_mask else 'âš ï¸  (dense model)'}\")\n",
    "\n",
    "    return {\n",
    "        \"path\": checkpoint_path,\n",
    "        \"has_encoder\": has_encoder,\n",
    "        \"has_classifier\": has_classifier,\n",
    "        \"has_mask\": has_mask,\n",
    "        \"sparsity\": sparsity if has_mask else 0.0,\n",
    "    }"
   ],
   "id": "2b8b63910b7a72e7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T14:47:21.775187Z",
     "start_time": "2025-11-09T14:47:21.766690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def verify_all_checkpoints(checkpoint_list):\n",
    "    \"\"\"Verify all checkpoints and create summary report.\"\"\"\n",
    "\n",
    "    print(\"\\n\" + \"ğŸ”¬\"*35)\n",
    "    print(\"LOTTERY TICKET CHECKPOINT VERIFICATION\")\n",
    "    print(\"ğŸ”¬\"*35)\n",
    "\n",
    "    results = []\n",
    "    for ckpt_path in checkpoint_list:\n",
    "        result = verify_checkpoint(ckpt_path)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "\n",
    "    # --- Summary Table ---\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ“Š SUMMARY TABLE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"{'Checkpoint':<50} {'Encoder':<10} {'Mask':<10} {'Sparsity':<10}\")\n",
    "    print(\"-\"*70)\n",
    "\n",
    "    for result in results:\n",
    "        name = os.path.basename(result[\"path\"])\n",
    "        encoder = \"âœ…\" if result[\"has_encoder\"] else \"âŒ\"\n",
    "        mask = \"âœ…\" if result[\"has_mask\"] else \"âš ï¸\"\n",
    "        sparsity = f\"{result['sparsity']:.1f}%\"\n",
    "        print(f\"{name:<50} {encoder:<10} {mask:<10} {sparsity:<10}\")\n",
    "\n",
    "    print(\"\\nâœ… Verification complete!\\n\")\n",
    "    return results"
   ],
   "id": "7160e2f409b0aacb",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T14:47:30.818312Z",
     "start_time": "2025-11-09T14:47:30.806809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_transfer_compatibility(source_checkpoint, target_task):\n",
    "    \"\"\"Check if a checkpoint is compatible for transfer to target task.\"\"\"\n",
    "\n",
    "    print(f\"\\nğŸ”„ Checking transfer compatibility:\")\n",
    "    print(f\"   Source: {os.path.basename(source_checkpoint)}\")\n",
    "    print(f\"   Target: {target_task.upper()}\")\n",
    "\n",
    "    ckpt = torch.load(source_checkpoint, map_location=\"cpu\")\n",
    "    state_dict = ckpt.get(\"model_state_dict\", {})\n",
    "\n",
    "    # Check BERT encoder\n",
    "    bert_keys = [k for k in state_dict.keys() if k.startswith(\"bert.\")]\n",
    "    if not bert_keys:\n",
    "        print(\"   âŒ No BERT encoder found!\")\n",
    "        return False\n",
    "\n",
    "    print(f\"   âœ… BERT encoder: {len(bert_keys)} parameters\")\n",
    "\n",
    "    # Check mask (for lottery tickets)\n",
    "    if \"mask_dict\" in ckpt:\n",
    "        mask_dict = ckpt[\"mask_dict\"]\n",
    "        total = sum(m.numel() for m in mask_dict.values())\n",
    "        nonzero = sum(m.sum().item() for m in mask_dict.values())\n",
    "        print(f\"   âœ… Lottery mask: {(1-nonzero/total)*100:.1f}% sparse\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸  No mask found (dense model)\")\n",
    "\n",
    "    # Check classifier (will be reinitialized anyway)\n",
    "    classifier_keys = [k for k in state_dict.keys() if k.startswith(\"classifier\")]\n",
    "    if classifier_keys:\n",
    "        print(f\"   â„¹ï¸  Classifier found (will be reinitialized for {target_task})\")\n",
    "\n",
    "    print(f\"   âœ… Compatible for transfer learning!\")\n",
    "    return True"
   ],
   "id": "68d82c8d5af920df",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T14:47:45.658350Z",
     "start_time": "2025-11-09T14:47:42.107946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Verify all checkpoints\n",
    "    results = verify_all_checkpoints(CHECKPOINTS)\n",
    "\n",
    "    # Test a few transfer scenarios\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ§ª TESTING TRANSFER SCENARIOS\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    test_scenarios = [\n",
    "        (\"./models/lottery_ticket_qqp_sparsity70_seed42.pt\", \"sst2\"),\n",
    "        (\"./models/lottery_ticket_sst2_sparsity60_seed42.pt\", \"qqp\"),\n",
    "        (\"./models/ensemble_ticket_sst2_qqp_sparsity47_seed42.pt\", \"sst2\"),\n",
    "    ]\n",
    "\n",
    "    for source, target in test_scenarios:\n",
    "        if os.path.exists(source):\n",
    "            check_transfer_compatibility(source, target)"
   ],
   "id": "80d2f0266b7efd92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬\n",
      "LOTTERY TICKET CHECKPOINT VERIFICATION\n",
      "ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬\n",
      "\n",
      "======================================================================\n",
      "ğŸ“¦ Inspecting: lottery_ticket_qqp_sparsity70_seed42.pt\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Checkpoint Keys:\n",
      "   - model_state_dict\n",
      "   - sparsity\n",
      "   - seed\n",
      "   - history\n",
      "\n",
      "ğŸ§  Model State Dict: 203 keys\n",
      "   - BERT encoder keys: 0\n",
      "   - Classifier keys: 0\n",
      "   - Other keys: 203\n",
      "\n",
      "   ğŸ”¬ Sample BERT weights (first 3):\n",
      "\n",
      "âš ï¸  No mask_dict found - this might be a dense model (sparsity 0)\n",
      "\n",
      "ğŸ“‹ Training Metadata:\n",
      "   - seed: 42\n",
      "   - sparsity: 0.7\n",
      "\n",
      "   Additional metadata:\n",
      "   - history: <class 'dict'>\n",
      "\n",
      "âœ… Verification Summary:\n",
      "   âœ“ BERT encoder weights: âŒ\n",
      "   âœ“ Classifier weights: âŒ\n",
      "   âœ“ Lottery ticket mask: âš ï¸  (dense model)\n",
      "\n",
      "======================================================================\n",
      "ğŸ“¦ Inspecting: lottery_ticket_sst2_sparsity60_seed42.pt\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Checkpoint Keys:\n",
      "   - model_state_dict\n",
      "   - sparsity\n",
      "   - seed\n",
      "   - history\n",
      "\n",
      "ğŸ§  Model State Dict: 203 keys\n",
      "   - BERT encoder keys: 0\n",
      "   - Classifier keys: 0\n",
      "   - Other keys: 203\n",
      "\n",
      "   ğŸ”¬ Sample BERT weights (first 3):\n",
      "\n",
      "âš ï¸  No mask_dict found - this might be a dense model (sparsity 0)\n",
      "\n",
      "ğŸ“‹ Training Metadata:\n",
      "   - seed: 42\n",
      "   - sparsity: 0.6\n",
      "\n",
      "   Additional metadata:\n",
      "   - history: <class 'dict'>\n",
      "\n",
      "âœ… Verification Summary:\n",
      "   âœ“ BERT encoder weights: âŒ\n",
      "   âœ“ Classifier weights: âŒ\n",
      "   âœ“ Lottery ticket mask: âš ï¸  (dense model)\n",
      "\n",
      "======================================================================\n",
      "ğŸ“¦ Inspecting: ensemble_ticket_sst2_qqp_sparsity47_seed42.pt\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Checkpoint Keys:\n",
      "   - model_state_dict\n",
      "   - source_a\n",
      "   - source_b\n",
      "   - seed\n",
      "   - sparsity\n",
      "   - tasks\n",
      "\n",
      "ğŸ§  Model State Dict: 203 keys\n",
      "   - BERT encoder keys: 0\n",
      "   - Classifier keys: 0\n",
      "   - Other keys: 203\n",
      "\n",
      "   ğŸ”¬ Sample BERT weights (first 3):\n",
      "\n",
      "âš ï¸  No mask_dict found - this might be a dense model (sparsity 0)\n",
      "\n",
      "ğŸ“‹ Training Metadata:\n",
      "   - seed: 42\n",
      "   - sparsity: 0.4694054029107775\n",
      "\n",
      "   Additional metadata:\n",
      "   - source_a: <class 'dict'>\n",
      "   - source_b: <class 'dict'>\n",
      "   - tasks: <class 'list'>\n",
      "\n",
      "âœ… Verification Summary:\n",
      "   âœ“ BERT encoder weights: âŒ\n",
      "   âœ“ Classifier weights: âŒ\n",
      "   âœ“ Lottery ticket mask: âš ï¸  (dense model)\n",
      "\n",
      "======================================================================\n",
      "ğŸ“¦ Inspecting: lottery_ticket_qqp_sparsity0_seed42.pt\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Checkpoint Keys:\n",
      "   - model_state_dict\n",
      "   - sparsity\n",
      "   - seed\n",
      "   - history\n",
      "\n",
      "ğŸ§  Model State Dict: 203 keys\n",
      "   - BERT encoder keys: 0\n",
      "   - Classifier keys: 0\n",
      "   - Other keys: 203\n",
      "\n",
      "   ğŸ”¬ Sample BERT weights (first 3):\n",
      "\n",
      "âš ï¸  No mask_dict found - this might be a dense model (sparsity 0)\n",
      "\n",
      "ğŸ“‹ Training Metadata:\n",
      "   - seed: 42\n",
      "   - sparsity: 0.0\n",
      "\n",
      "   Additional metadata:\n",
      "   - history: <class 'dict'>\n",
      "\n",
      "âœ… Verification Summary:\n",
      "   âœ“ BERT encoder weights: âŒ\n",
      "   âœ“ Classifier weights: âŒ\n",
      "   âœ“ Lottery ticket mask: âš ï¸  (dense model)\n",
      "\n",
      "======================================================================\n",
      "ğŸ“¦ Inspecting: lottery_ticket_sst2_sparsity0_seed42.pt\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Checkpoint Keys:\n",
      "   - model_state_dict\n",
      "   - sparsity\n",
      "   - seed\n",
      "   - history\n",
      "\n",
      "ğŸ§  Model State Dict: 203 keys\n",
      "   - BERT encoder keys: 0\n",
      "   - Classifier keys: 0\n",
      "   - Other keys: 203\n",
      "\n",
      "   ğŸ”¬ Sample BERT weights (first 3):\n",
      "\n",
      "âš ï¸  No mask_dict found - this might be a dense model (sparsity 0)\n",
      "\n",
      "ğŸ“‹ Training Metadata:\n",
      "   - seed: 42\n",
      "   - sparsity: 0.0\n",
      "\n",
      "   Additional metadata:\n",
      "   - history: <class 'dict'>\n",
      "\n",
      "âœ… Verification Summary:\n",
      "   âœ“ BERT encoder weights: âŒ\n",
      "   âœ“ Classifier weights: âŒ\n",
      "   âœ“ Lottery ticket mask: âš ï¸  (dense model)\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š SUMMARY TABLE\n",
      "======================================================================\n",
      "Checkpoint                                         Encoder    Mask       Sparsity  \n",
      "----------------------------------------------------------------------\n",
      "lottery_ticket_qqp_sparsity70_seed42.pt            âŒ          âš ï¸         0.0%      \n",
      "lottery_ticket_sst2_sparsity60_seed42.pt           âŒ          âš ï¸         0.0%      \n",
      "ensemble_ticket_sst2_qqp_sparsity47_seed42.pt      âŒ          âš ï¸         0.0%      \n",
      "lottery_ticket_qqp_sparsity0_seed42.pt             âŒ          âš ï¸         0.0%      \n",
      "lottery_ticket_sst2_sparsity0_seed42.pt            âŒ          âš ï¸         0.0%      \n",
      "\n",
      "âœ… Verification complete!\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ğŸ§ª TESTING TRANSFER SCENARIOS\n",
      "======================================================================\n",
      "\n",
      "ğŸ”„ Checking transfer compatibility:\n",
      "   Source: lottery_ticket_qqp_sparsity70_seed42.pt\n",
      "   Target: SST2\n",
      "   âŒ No BERT encoder found!\n",
      "\n",
      "ğŸ”„ Checking transfer compatibility:\n",
      "   Source: lottery_ticket_sst2_sparsity60_seed42.pt\n",
      "   Target: QQP\n",
      "   âŒ No BERT encoder found!\n",
      "\n",
      "ğŸ”„ Checking transfer compatibility:\n",
      "   Source: ensemble_ticket_sst2_qqp_sparsity47_seed42.pt\n",
      "   Target: SST2\n",
      "   âŒ No BERT encoder found!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fad7817ed3605679"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Winning-Ticket",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
